{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Points import Points\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {\"anger\": 0, \"contempt\": 1, \"disgust\": 2, \"fear\": 3, \"happiness\": 4, \"neutral\": 5, \"sadness\": 6,\"sad\": 6,\n",
    "            \"surprise\": 6}\n",
    "\n",
    "def read_data(path, label_points):\n",
    "    '''Path for json with '''\n",
    "    landmarks = pd.read_json(path)\n",
    "    emotions = np.asarray([emotion_dict[y] for y in landmarks.iloc[0].astype(object)], dtype=np.float32)\n",
    "    columns = landmarks.shape[1]\n",
    "    points = []\n",
    "    for photo in range(columns):\n",
    "        for point in label_points:\n",
    "            coords = landmarks[photo].iloc[point+1][0:2]\n",
    "            points.extend(coords)\n",
    "\n",
    "    points = np.array(points, dtype=np.float32).reshape(1133, len(label_points*2))\n",
    "\n",
    "    print(f\"shape at the end: {points.shape}\")\n",
    "    return emotions, points\n",
    "    #return [[a, b] for (a, b) in zip(np.concatenate((JAFFE_EMO, CK_EMO)), np.concatenate((JAFFE_VEC, CK_VEC)))] #\n",
    "    \n",
    "def select_points(emotions, points, training_ratio):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(points, emotions, \n",
    "                                                        test_size=(1-training_ratio), random_state=1234)\n",
    "    \n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    \n",
    "    new_y_train = np.zeros([y_train.shape[0], 7])\n",
    "    for index in range(y_train.shape[0]):\n",
    "        if int(y_train[index]) != emotion_dict[\"neutral\"]:\n",
    "            new_y_train[index][int(y_train[index])] = 10\n",
    "    \n",
    "    new_y_test = np.zeros([y_test.shape[0], 7])\n",
    "    for index in range(y_test.shape[0]):\n",
    "        if int(y_test[index]) != emotion_dict[\"neutral\"]:\n",
    "            new_y_test[index][int(y_test[index])] = 10\n",
    "        \n",
    "    \n",
    "    y_train = torch.from_numpy(new_y_train)\n",
    "    y_test = torch.from_numpy(new_y_test)\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net model\n",
    "\n",
    "# 1) Model\n",
    "# Linear model f = wx + b , sigmoid at the end\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 268)\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Model(268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape at the end: (1133, 268)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Forward pass and loss\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[0;32m---> 20\u001b[0m     new_label \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1076\u001b[39m,\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m     21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(new_pred, new_label)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Backward pass and update\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "# 1)\n",
    "min_wanted_points = Points.right_eye_middle.value + Points.left_eye_middle.value + Points.nose.value + Points.mouth_inner.value\n",
    "max_wanted_points = min_wanted_points + Points.right_eye_inner.value + Points.right_eye_outer.value + \\\n",
    "        Points.left_eye_inner.value + Points.left_eye_outer.value\n",
    "\n",
    "emotions, points = read_data(\"./photo_landmark_list.json\", max_wanted_points)\n",
    "X_train, X_test, y_train, y_test = select_points(emotions, points, .95)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    new_label = torch.from_numpy(y_train).float().view(1076,7)\n",
    "    loss = criterion(new_pred, new_label)\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        y_predicted = model(X_test)\n",
    "        for row in range(y_predicted.shape[0]):\n",
    "            dist = 100\n",
    "            closest_index = None\n",
    "            for index in range(7):\n",
    "                if abs(float(y_predicted[row][index])-10) < dist:\n",
    "                    dist = abs(float(y_predicted[row][index])-10)\n",
    "                    closest_index = index\n",
    "            if closest_index == y_test[row]:\n",
    "                correct += 1\n",
    "\n",
    "        print(f\"correct: {correct}\")\n",
    "        print(f\"total: {y_predicted.shape[0]}\")\n",
    "\n",
    "#torch.save(model.state_dict(), \"./model-v10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
